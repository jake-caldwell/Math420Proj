---
title: "Math 420 Final Project"
author: "Riley Coburn"
date: "12/14/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(mosaic)
require(agricolae) #possible desired package for LSD; will need to install first time around
require(Stat2Data)
require(car)
require(nortest)
require(fBasics) # needed for more advanced normality tests, e.g. D'Agostino's
```

```{r}
set.seed(10)
runs <- 100000

xs <- runif(runs,min=-0.5,max=0.5) #uniform distribution
ys <- runif(runs,min=-0.5,max=0.5) #uniform distribution

#we are randomly sampling from two uniform distributions

in.circle <- xs^2 + ys^2 <= 0.5^2 #calculating test statistic i.e. whether a randomly sampled point from our uniform distributions falls within the circle inscribed in the sampling distribution

#Empirically, A_square = (2r)^2 = 4r^2. Suppose we don't know a value for pi, but instead just know that A_circle is proportional to r^2. That is A_circle = cr^2. If we were to 

mc.pi <- (sum(in.circle)/runs)*4 #Finding proportion of points of the square that lie within the circle. We multiply by a factor of 4 because the proportion of areas is A_square/A_circle = 4r^2/cr^2 = 4/c meaning c = 4*A_circle/A_square. Here, A_cirle is just the number of points that we have inside the circle and A-square is just all points as the sampling distribution is a square. 
plot(xs,ys,pch='.',col=ifelse(in.circle,"blue","grey")
     ,xlab='',ylab='',asp=1,
     main=paste("MC Approximation of Pi =",mc.pi))
```
### Simple Randomization Based Inference using cancer survival data.

```{r}
Cancer = read.csv("http://personal.denison.edu/~whiteda/files/Teaching/CancerSurvival.csv") # reads in the data
fv = favstats(~Survival | Organ, data=Cancer) # provides summary stats for survival for each type of cancer in data
fv
bwplot(~Survival | Organ, data=Cancer, layout = c(1, 5)) # plots the distribution of survival for each type of cancer in a boxplot
```


```{r}
mod <- aov(Survival~Organ, data = Cancer) # generates our original model to get our original test stat
summary(mod) # summary of above model
plot(mod, which = 1) # plots residuals vs fitted values, check for equal variance
plot(mod, which = 2) # plots normal-qq, check for noramlly distributed residuals
leveneTest(mod) # Levene's test for equal variances of groups
shapiro.test(mod$residuals) # shapiro wilkes test for normality of residuals

```

Normality of residuals and equal variance conditions not met, so we will test for randomness:

```{r}
library(lawstat)
runs.test(Cancer$Survival)
bartels.test(Cancer$Survival)
```

We fail to reject the null hypothesis that the data is not normal, we can proceed with randomization based inference. 

```{r}
mod=lm(Survival~Organ,data=Cancer)# our original mod
anova(mod) # anova to determine utility
res=anova(mod)$"F value"# store the F statistics
t=do(1000)*(anova(lm(shuffle(Survival)~as.factor(Organ),data=Cancer))$"F value")# repeat above process 1000 times with shuffled response variable. 
t=as.data.frame(t)# generates a dataframe of the randomization distribution
densityplot(~V1, data=t) #plots this in a density plot
ladd(panel.abline(v=res[1], col="red", lwd=3)) #adds a line in for our original F-stat
results <- pdata(res[1],t$V1,data=t,lower.tail=FALSE) # generating the number of F-stats as or more extreme than our original
length(subset(results,results==0))/length(results) # empirical p-value
```

After 1000 permutations, we have come to the conclusion to reject the null hypothesis that the different types of cancers in the data set have the same mean survival rate. Our above randomization distribution essentially says our p-value given our original F-statistic is 0. 

## Testing the Asymptotic Null 

Above, we ran the shuffled model 1000 times, what if we ran it 100, 500, 1000, 5000, and 10000 times, would the p-value converge?

```{r}
set.seed(5)
# 100 times
mod=lm(Survival~Organ,data=Cancer)# our original mod
anova(mod) # anova to determine utility
res1=anova(mod)$"F value"# store the F statistics
t1=do(100)*(anova(lm(shuffle(Survival)~as.factor(Organ),data=Cancer))$"F value")# repeat above process 1000 times with shuffled response variable. 
t1=as.data.frame(t1)# generates a dataframe of the randomization distribution
densityplot(~V1, data=t1) #plots this in a density plot
ladd(panel.abline(v=res1[1], col="red", lwd=3)) #adds a line in for our original F-stat
results <- pdata(res1[1],t1$V1,data=t1,lower.tail=FALSE) # generating the number of F-stats as or more extreme than our original
length(subset(results,results==0))/length(results) # empirical p-value
```

When run 100 times, the distribution couldn't even display our original F-stat, it was too big for the plot!

We can try again with 500 runs:

```{r}
set.seed(5)
mod=lm(Survival~Organ,data=Cancer)# our original mod
anova(mod) # anova to determine utility
res2=anova(mod)$"F value"# store the F statistics
t2=do(500)*(anova(lm(shuffle(Survival)~as.factor(Organ),data=Cancer))$"F value")# repeat above process 1000 times with shuffled response variable. 
t2=as.data.frame(t2)# generates a dataframe of the randomization distribution
densityplot(~V1, data=t2) #plots this in a density plot
ladd(panel.abline(v=res2[1], col="red", lwd=3)) #adds a line in for our original F-stat
results <- pdata(res2[1],t2$V1,data=t2,lower.tail=FALSE) # generating the number of F-stats as or more extreme than our original
length(subset(results,results==0))/length(results) # empirical p-value
```
We are getting closer, but still our original F-stat was too large, so doesn't appear in the plot, we have already tried 1000, so let's go for 2500. 

```{r}
set.seed(5)
mod=lm(Survival~Organ,data=Cancer)# our original mod
anova(mod) # anova to determine utility
res3=anova(mod)$"F value"# store the F statistics
t3=do(2500)*(anova(lm(shuffle(Survival)~as.factor(Organ),data=Cancer))$"F value")# repeat above process 1000 times with shuffled response variable. 
t3=as.data.frame(t3)# generates a dataframe of the randomization distribution
densityplot(~V1, data=t3) #plots this in a density plot
ladd(panel.abline(v=res3[1], col="red", lwd=3)) #adds a line in for our original F-stat
results <- pdata(res3[1],t3$V1,data=t3,lower.tail=FALSE) # generating the number of F-stats as or more extreme than our original
length(subset(results,results==0))/length(results) # empirical p-value
```
At 2500 runs, we get a p-value of .0016. Which is larger than 0, but what are the chances our actual results are the first of their kind? Let's try 5000:

```{r}
set.seed(5)
mod=lm(Survival~Organ,data=Cancer)# our original mod
anova(mod) # anova to determine utility
res4=anova(mod)$"F value"# store the F statistics
t4=do(5000)*(anova(lm(shuffle(Survival)~as.factor(Organ),data=Cancer))$"F value")# repeat above process 1000 times with shuffled response variable. 
t4=as.data.frame(t4)# generates a dataframe of the randomization distribution
densityplot(~V1, data=t4) #plots this in a density plot
ladd(panel.abline(v=res4[1], col="red", lwd=3)) #adds a line in for our original F-stat
results <- pdata(res4[1],t4$V1,data=t4,lower.tail=FALSE) # generating the number of F-stats as or more extreme than our original
length(subset(results,results==0))/length(results) # empirical p-value
```
Okay, now our p-value is starting to take shape. We got a .0014, which is close to .0016, so maybe we are approaching our asymptote. Let's go real big and try 10000:

```{r}
set.seed(5)
mod=lm(Survival~Organ,data=Cancer)# our original mod
anova(mod) # anova to determine utility
res5=anova(mod)$"F value"# store the F statistics
t5=do(10000)*(anova(lm(shuffle(Survival)~as.factor(Organ),data=Cancer))$"F value")# repeat above process 1000 times with shuffled response variable. 
t5=as.data.frame(t5)# generates a dataframe of the randomization distribution
densityplot(~V1, data=t5) #plots this in a density plot
ladd(panel.abline(v=res[1], col="red", lwd=3)) #adds a line in for our original F-stat
results <- pdata(res5[1],t5$V1,data=t5,lower.tail=FALSE) # generating the number of F-stats as or more extreme than our original
length(subset(results,results==0))/length(results) # empirical p-value
```




